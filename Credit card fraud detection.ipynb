{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6152fed-cc62-4139-93f9-2cd12806aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c04807-a9c1-48b7-9e44-6715530b8630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/92/2d/880fcd65e4414b05088193e6f2cfb86fdf90003dd2dd0f4d1bc465348f0e/tensorflow-2.15.0-cp311-cp311-macosx_10_15_x86_64.whl.metadata\n",
      "  Using cached tensorflow-2.15.0-cp311-cp311-macosx_10_15_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow)\n",
      "  Obtaining dependency information for h5py>=2.9.0 from https://files.pythonhosted.org/packages/c3/99/570fedd40048daeb04d4738ed4f1d0e77259fb631387f7f188aac3d85c31/h5py-3.10.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Using cached h5py-3.10.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/c9/ea/fe2a69cc6cfebf7c7ee8a6357566fc1cbb91632bde5869b669a396accb5f/libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl.metadata\n",
      "  Using cached libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes~=0.2.0 from https://files.pythonhosted.org/packages/15/da/43bee505963da0c730ee50e951c604bfdb90d4cccc9c0044c946b10e68a7/ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Using cached ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.25.2)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/b3/81/0017aefacf23273d4efd1154ef958a27eed9c177c4cc09d2d4ba398fb47f/protobuf-4.25.2-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Using cached protobuf-4.25.2-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl.metadata\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow)\n",
      "  Obtaining dependency information for typing-extensions>=3.6.6 from https://files.pythonhosted.org/packages/b7/f4/6a90020cd2d93349b442bfcb657d0dc91eee65491600b2cb1d388bc98e6b/typing_extensions-4.9.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow)\n",
      "  Obtaining dependency information for wrapt<1.15,>=1.11.0 from https://files.pythonhosted.org/packages/e7/f9/8c078b4973604cd968b23eb3dff52028b5c48f2a02c4f1f975f4d5e344d1/wrapt-1.14.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Using cached wrapt-1.14.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/ad/e3/1009781ce3c0d92634fa2fb3dc4bb0237fe7aaf70f2ab53160f3e82e7d63/tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-macosx_10_14_x86_64.whl.metadata\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-macosx_10_14_x86_64.whl.metadata (14 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/ec/d5/c3ddb54b39ce43d21428407eb26cf9a21fd43de5e26d9733b1f173d57475/grpcio-1.60.1-cp311-cp311-macosx_10_10_universal2.whl.metadata\n",
      "  Using cached grpcio-1.60.1-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.16,>=2.15 from https://files.pythonhosted.org/packages/37/12/f6e9b9dcc310263cbd3948274e286538bd6800fd0c268850788f14a0c6d0/tensorboard-2.15.2-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/b6/c8/2f823c8958d5342eafc6dd3e922f0cc4fcf8c2e0460284cc462dae3b60a0/tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow)\n",
      "  Obtaining dependency information for keras<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/fc/a7/0d4490de967a67f68a538cc9cdb259bff971c4b5787f7765dc7c8f118f71/keras-2.15.0-py3-none-any.whl.metadata\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Obtaining dependency information for wheel<1.0,>=0.23.0 from https://files.pythonhosted.org/packages/c7/c3/55076fc728723ef927521abaa1955213d094933dc36d4a2008d5101e1af5/wheel-0.42.0-py3-none-any.whl.metadata\n",
      "  Using cached wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/82/41/7fb855444cead5b2213e053447ce3a0b7bf2c3529c443e0cf75b2f13b405/google_auth-2.27.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_auth-2.27.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Obtaining dependency information for google-auth-oauthlib<2,>=0.5 from https://files.pythonhosted.org/packages/71/bf/9e125754d1adb3bc4bd206c4e5df756513b1d23675ac06caa471278d1f3f/google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/42/f4/f0031854de10a0bc7821ef9fca0b92ca0d7aa6fbfbf504c5473ba825e49c/Markdown-3.5.2-py3-none-any.whl.metadata\n",
      "  Using cached Markdown-3.5.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/b7/85/dabeaf902892922777492e1d253bb7e1264cadce3cea932f7ff599e53fea/tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/c3/fc/254c3e9b5feb89ff5b9076a23218dafbc99c96ac5941e900b71206e6313b/werkzeug-3.0.1-py3-none-any.whl.metadata\n",
      "  Using cached werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a2/91/2d843adb9fbd911e0da45fbf6f18ca89d07a087c3daa23e955584f90ebf4/cachetools-5.3.2-py3-none-any.whl.metadata\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Obtaining dependency information for pyasn1<0.6.0,>=0.4.6 from https://files.pythonhosted.org/packages/d1/75/4686d2872bf2fc0b37917cbc8bbf0dd3a5cdb0990799be1b9cbf1e1eb733/pyasn1-0.5.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "Downloading tensorflow-2.15.0-cp311-cp311-macosx_10_15_x86_64.whl (239.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.1/239.1 MB\u001b[0m \u001b[31m185.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:21\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m692.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.60.1-cp311-cp311-macosx_10_10_universal2.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m339.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.10.0-cp311-cp311-macosx_10_9_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m395.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m486.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m350.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m362.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.2-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m367.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m388.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m268.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.36.0-cp311-cp311-macosx_10_14_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m358.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading wrapt-1.14.1-cp311-cp311-macosx_10_9_x86_64.whl (35 kB)\n",
      "Downloading google_auth-2.27.0-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.8/186.8 kB\u001b[0m \u001b[31m323.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m238.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m436.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m222.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m229.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, wheel, werkzeug, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, ml-dtypes, markdown, keras, h5py, grpcio, google-pasta, gast, cachetools, absl-py, rsa, pyasn1-modules, astunparse, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.15.0\n",
      "    Uninstalling wrapt-1.15.0:\n",
      "      Successfully uninstalled wrapt-1.15.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.27.0 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.1 h5py-3.10.0 keras-2.15.0 libclang-16.0.6 markdown-3.5.2 ml-dtypes-0.2.0 opt-einsum-3.3.0 protobuf-4.25.2 pyasn1-0.5.1 pyasn1-modules-0.3.0 rsa-4.9 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0 typing-extensions-4.9.0 werkzeug-3.0.1 wheel-0.42.0 wrapt-1.14.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d7f46a-0e27-4826-aba2-ac8ba498280e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"creditcard.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb36169-57ed-47b5-9f37-b10d711a9fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Class 0 is for not fraud and 1 is for fraud\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82cdf567-46a2-4ed5-aad0-9e29326036ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Amount          Class\n",
       "count  284807.000000  284807.000000\n",
       "mean       88.349619       0.001727\n",
       "std       250.120109       0.041527\n",
       "min         0.000000       0.000000\n",
       "25%         5.600000       0.000000\n",
       "50%        22.000000       0.000000\n",
       "75%        77.165000       0.000000\n",
       "max     25691.160000       1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_two_columns = df.iloc[:, -2:]\n",
    "last_two_columns.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd9687d2-91a0-4656-85ad-4cd0fe09643e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'Amount'}>,\n",
       "        <Axes: title={'center': 'Class'}>]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "last_two_columns.hist(bins=30, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1956ce7e-1cd4-41d0-a3d4-901d101ce885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>1.783274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.269825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>4.983721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>1.418291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>0.999965</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>-0.296653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>0.999971</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>0.999977</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>0.641096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>0.999977</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>-0.167680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>2.724796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0       0.000000  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1       0.000000   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2       0.000006  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3       0.000006  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4       0.000012  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  0.999965 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  0.999971  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  0.999977   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  0.999977  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  1.000000  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  1.783274   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.269825   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  4.983721   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  1.418291   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153  0.670579   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731 -0.296653   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527  0.038986   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561  0.641096   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533 -0.167680   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  2.724796   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data is extremerly imbalced we have to balance the data to train it in models\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "new_df = df.copy()\n",
    "new_df['Amount'] = RobustScaler().fit_transform(new_df['Amount'].to_numpy().reshape(-1, 1))\n",
    "time = new_df['Time']\n",
    "new_df['Time'] = (time - time.min()) / (time.max() - time.min())\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33be997c-bca4-49ee-80f4-829e19c9a305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df['Amount'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e4f2b1f-ff56-4635-8fba-faf54a5fc560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169876</th>\n",
       "      <td>0.693938</td>\n",
       "      <td>-0.611712</td>\n",
       "      <td>-0.769705</td>\n",
       "      <td>-0.149759</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>2.028577</td>\n",
       "      <td>-2.019887</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>-0.523020</td>\n",
       "      <td>0.358468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075208</td>\n",
       "      <td>0.045536</td>\n",
       "      <td>0.380739</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>-2.220686</td>\n",
       "      <td>-0.201146</td>\n",
       "      <td>0.066501</td>\n",
       "      <td>0.221180</td>\n",
       "      <td>-0.282401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127467</th>\n",
       "      <td>0.453377</td>\n",
       "      <td>-0.814682</td>\n",
       "      <td>1.319219</td>\n",
       "      <td>1.329415</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.284871</td>\n",
       "      <td>-0.653985</td>\n",
       "      <td>0.321552</td>\n",
       "      <td>0.435975</td>\n",
       "      <td>-0.704298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128619</td>\n",
       "      <td>-0.368565</td>\n",
       "      <td>0.090660</td>\n",
       "      <td>0.401147</td>\n",
       "      <td>-0.261034</td>\n",
       "      <td>0.080621</td>\n",
       "      <td>0.162427</td>\n",
       "      <td>0.059456</td>\n",
       "      <td>-0.279746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137900</th>\n",
       "      <td>0.476770</td>\n",
       "      <td>-0.318193</td>\n",
       "      <td>1.118618</td>\n",
       "      <td>0.969864</td>\n",
       "      <td>-0.127052</td>\n",
       "      <td>0.569563</td>\n",
       "      <td>-0.532484</td>\n",
       "      <td>0.706252</td>\n",
       "      <td>-0.064966</td>\n",
       "      <td>-0.463271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305402</td>\n",
       "      <td>-0.774704</td>\n",
       "      <td>-0.123884</td>\n",
       "      <td>-0.495687</td>\n",
       "      <td>-0.018148</td>\n",
       "      <td>0.121679</td>\n",
       "      <td>0.249050</td>\n",
       "      <td>0.092516</td>\n",
       "      <td>-0.294977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21513</th>\n",
       "      <td>0.183556</td>\n",
       "      <td>-1.328271</td>\n",
       "      <td>1.018378</td>\n",
       "      <td>1.775426</td>\n",
       "      <td>-1.574193</td>\n",
       "      <td>-0.117696</td>\n",
       "      <td>-0.457733</td>\n",
       "      <td>0.681867</td>\n",
       "      <td>-0.031641</td>\n",
       "      <td>0.383872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220815</td>\n",
       "      <td>-0.419013</td>\n",
       "      <td>-0.239197</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.232829</td>\n",
       "      <td>0.814177</td>\n",
       "      <td>0.098797</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>-0.084119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134700</th>\n",
       "      <td>0.468326</td>\n",
       "      <td>1.276712</td>\n",
       "      <td>0.617120</td>\n",
       "      <td>-0.578014</td>\n",
       "      <td>0.879173</td>\n",
       "      <td>0.061706</td>\n",
       "      <td>-1.472002</td>\n",
       "      <td>0.373692</td>\n",
       "      <td>-0.287204</td>\n",
       "      <td>-0.084482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160161</td>\n",
       "      <td>-0.430404</td>\n",
       "      <td>-0.076738</td>\n",
       "      <td>0.258708</td>\n",
       "      <td>0.552170</td>\n",
       "      <td>0.370701</td>\n",
       "      <td>-0.034255</td>\n",
       "      <td>0.041709</td>\n",
       "      <td>-0.296793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21440</th>\n",
       "      <td>0.183261</td>\n",
       "      <td>-2.986845</td>\n",
       "      <td>-8.663978</td>\n",
       "      <td>-1.910863</td>\n",
       "      <td>0.664058</td>\n",
       "      <td>-3.934875</td>\n",
       "      <td>0.861269</td>\n",
       "      <td>1.647511</td>\n",
       "      <td>-0.480963</td>\n",
       "      <td>-1.546866</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252092</td>\n",
       "      <td>-0.993085</td>\n",
       "      <td>-2.173147</td>\n",
       "      <td>0.145570</td>\n",
       "      <td>-0.235062</td>\n",
       "      <td>-0.227411</td>\n",
       "      <td>-0.382702</td>\n",
       "      <td>0.404045</td>\n",
       "      <td>32.002515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117583</th>\n",
       "      <td>0.432480</td>\n",
       "      <td>0.937083</td>\n",
       "      <td>-0.849673</td>\n",
       "      <td>0.524186</td>\n",
       "      <td>-0.020031</td>\n",
       "      <td>-0.606327</td>\n",
       "      <td>0.692302</td>\n",
       "      <td>-0.463724</td>\n",
       "      <td>0.148857</td>\n",
       "      <td>0.785062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143322</td>\n",
       "      <td>-0.479981</td>\n",
       "      <td>-0.237902</td>\n",
       "      <td>-0.715247</td>\n",
       "      <td>0.251418</td>\n",
       "      <td>0.975406</td>\n",
       "      <td>-0.060168</td>\n",
       "      <td>0.023771</td>\n",
       "      <td>2.086495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73349</th>\n",
       "      <td>0.318852</td>\n",
       "      <td>-1.149963</td>\n",
       "      <td>1.696462</td>\n",
       "      <td>1.637114</td>\n",
       "      <td>2.658991</td>\n",
       "      <td>-0.021502</td>\n",
       "      <td>0.192287</td>\n",
       "      <td>0.205204</td>\n",
       "      <td>0.588754</td>\n",
       "      <td>-1.187820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025147</td>\n",
       "      <td>0.086506</td>\n",
       "      <td>-0.262748</td>\n",
       "      <td>0.321538</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.210343</td>\n",
       "      <td>-0.162047</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>-0.201495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267336</th>\n",
       "      <td>0.941757</td>\n",
       "      <td>1.754554</td>\n",
       "      <td>-0.699398</td>\n",
       "      <td>-0.076332</td>\n",
       "      <td>0.443915</td>\n",
       "      <td>-0.672082</td>\n",
       "      <td>0.389061</td>\n",
       "      <td>-0.807534</td>\n",
       "      <td>0.202915</td>\n",
       "      <td>0.858635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141950</td>\n",
       "      <td>0.358412</td>\n",
       "      <td>0.259748</td>\n",
       "      <td>0.746839</td>\n",
       "      <td>-0.560808</td>\n",
       "      <td>0.104636</td>\n",
       "      <td>-0.005853</td>\n",
       "      <td>-0.019622</td>\n",
       "      <td>1.017257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>0.454743</td>\n",
       "      <td>-0.707635</td>\n",
       "      <td>0.493302</td>\n",
       "      <td>2.648089</td>\n",
       "      <td>1.064807</td>\n",
       "      <td>-0.680271</td>\n",
       "      <td>1.183838</td>\n",
       "      <td>0.169413</td>\n",
       "      <td>0.074553</td>\n",
       "      <td>1.247988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102350</td>\n",
       "      <td>0.323975</td>\n",
       "      <td>-0.172601</td>\n",
       "      <td>0.126965</td>\n",
       "      <td>-0.001998</td>\n",
       "      <td>-0.398741</td>\n",
       "      <td>-0.385589</td>\n",
       "      <td>-0.205589</td>\n",
       "      <td>0.500245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "169876  0.693938 -0.611712 -0.769705 -0.149759 -0.224877  2.028577 -2.019887   \n",
       "127467  0.453377 -0.814682  1.319219  1.329415  0.027273 -0.284871 -0.653985   \n",
       "137900  0.476770 -0.318193  1.118618  0.969864 -0.127052  0.569563 -0.532484   \n",
       "21513   0.183556 -1.328271  1.018378  1.775426 -1.574193 -0.117696 -0.457733   \n",
       "134700  0.468326  1.276712  0.617120 -0.578014  0.879173  0.061706 -1.472002   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "21440   0.183261 -2.986845 -8.663978 -1.910863  0.664058 -3.934875  0.861269   \n",
       "117583  0.432480  0.937083 -0.849673  0.524186 -0.020031 -0.606327  0.692302   \n",
       "73349   0.318852 -1.149963  1.696462  1.637114  2.658991 -0.021502  0.192287   \n",
       "267336  0.941757  1.754554 -0.699398 -0.076332  0.443915 -0.672082  0.389061   \n",
       "128037  0.454743 -0.707635  0.493302  2.648089  1.064807 -0.680271  1.183838   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "169876  0.292491 -0.523020  0.358468  ... -0.075208  0.045536  0.380739   \n",
       "127467  0.321552  0.435975 -0.704298  ... -0.128619 -0.368565  0.090660   \n",
       "137900  0.706252 -0.064966 -0.463271  ... -0.305402 -0.774704 -0.123884   \n",
       "21513   0.681867 -0.031641  0.383872  ... -0.220815 -0.419013 -0.239197   \n",
       "134700  0.373692 -0.287204 -0.084482  ... -0.160161 -0.430404 -0.076738   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "21440   1.647511 -0.480963 -1.546866  ...  1.252092 -0.993085 -2.173147   \n",
       "117583 -0.463724  0.148857  0.785062  ... -0.143322 -0.479981 -0.237902   \n",
       "73349   0.205204  0.588754 -1.187820  ...  0.025147  0.086506 -0.262748   \n",
       "267336 -0.807534  0.202915  0.858635  ...  0.141950  0.358412  0.259748   \n",
       "128037  0.169413  0.074553  1.247988  ... -0.102350  0.323975 -0.172601   \n",
       "\n",
       "             V24       V25       V26       V27       V28     Amount  Class  \n",
       "169876  0.023440 -2.220686 -0.201146  0.066501  0.221180  -0.282401      0  \n",
       "127467  0.401147 -0.261034  0.080621  0.162427  0.059456  -0.279746      0  \n",
       "137900 -0.495687 -0.018148  0.121679  0.249050  0.092516  -0.294977      0  \n",
       "21513   0.009967  0.232829  0.814177  0.098797 -0.004273  -0.084119      0  \n",
       "134700  0.258708  0.552170  0.370701 -0.034255  0.041709  -0.296793      0  \n",
       "...          ...       ...       ...       ...       ...        ...    ...  \n",
       "21440   0.145570 -0.235062 -0.227411 -0.382702  0.404045  32.002515      0  \n",
       "117583 -0.715247  0.251418  0.975406 -0.060168  0.023771   2.086495      0  \n",
       "73349   0.321538  0.341667  0.210343 -0.162047  0.031193  -0.201495      0  \n",
       "267336  0.746839 -0.560808  0.104636 -0.005853 -0.019622   1.017257      0  \n",
       "128037  0.126965 -0.001998 -0.398741 -0.385589 -0.205589   0.500245      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = new_df.sample(frac=1, random_state=1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfaa07c9-2882-408f-a1d0-514344ea825e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Class\n",
       " 0    199004\n",
       " 1       360\n",
       " Name: count, dtype: int64,\n",
       " Class\n",
       " 0    56865\n",
       " 1       97\n",
       " Name: count, dtype: int64,\n",
       " Class\n",
       " 0    28446\n",
       " 1       35\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Splitting into train and temp sets (70% train, 30% temp)\n",
    "train, temp = train_test_split(new_df, test_size=0.3, random_state=42)\n",
    "# Splitting temp into test and validation sets (20% test, 10% validation)\n",
    "test, val = train_test_split(temp, test_size=1/3, random_state=42)\n",
    "train['Class'].value_counts(), test['Class'].value_counts(), val['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a261c5-1bd3-409b-a47f-325dced5c884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199364, 31), (56962, 31), (28481, 31))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_np, test_np, val_np = train.to_numpy(), test.to_numpy(), val.to_numpy()\n",
    "train_np.shape, test_np.shape, val_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "850804e9-a8b6-4758-ad25-993703c89828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199364, 30), (199364,), (56962, 30), (56962,), (28481, 30), (28481,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = train_np[:, :-1], train_np[:, -1]\n",
    "x_test, y_test = test_np[:, :-1], test_np[:, -1]\n",
    "x_val, y_val = val_np[:, :-1], val_np[:, -1]\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "707dd925-14a4-4845-8519-9f05969e9b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991673521799321"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(x_train, y_train)\n",
    "logistic_model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5090d74b-c70c-4bed-8da4-8917628bb353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     28446\n",
      "       Fraud       0.81      0.49      0.61        35\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.90      0.74      0.80     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val, logistic_model.predict(x_val), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c11b854e-295f-4e6d-b437-714ae5e788a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is less for fraud so the accuracy of this feature is less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e42b1571-e9a5-441e-9216-c79fa3982bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "shallow_nn = Sequential()\n",
    "shallow_nn.add(InputLayer((x_train.shape[1],)))\n",
    "shallow_nn.add(Dense(2, 'relu'))\n",
    "shallow_nn.add(BatchNormalization())\n",
    "shallow_nn.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "checkpoint = ModelCheckpoint('shallow_nn', save_best_only=True)\n",
    "shallow_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d64b3ba0-017b-4636-bc99-8055231b9187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2)                 62        \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2)                 8         \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73 (292.00 Byte)\n",
      "Trainable params: 69 (276.00 Byte)\n",
      "Non-trainable params: 4 (16.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shallow_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a057824-a9db-4dcd-a1e0-10f2ff85994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6227/6231 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 0.9777INFO:tensorflow:Assets written to: shallow_nn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6231/6231 [==============================] - 48s 7ms/step - loss: 0.0643 - accuracy: 0.9777 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "Epoch 2/5\n",
      "6231/6231 [==============================] - 53s 9ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 3/5\n",
      "6230/6231 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993INFO:tensorflow:Assets written to: shallow_nn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6231/6231 [==============================] - 34s 5ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0030 - val_accuracy: 0.9995\n",
      "Epoch 4/5\n",
      "6230/6231 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9993INFO:tensorflow:Assets written to: shallow_nn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6231/6231 [==============================] - 35s 6ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 5/5\n",
      "6231/6231 [==============================] - 38s 6ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0031 - val_accuracy: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x12f9365d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_nn.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5, callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8a91c15-b675-4df1-9d6a-0d8faba562a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 5s 4ms/step\n",
      "891/891 [==============================] - 2s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     28446\n",
      "       Fraud       0.79      0.77      0.78        35\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.90      0.89      0.89     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating the prediction function, flatten the file \n",
    "def neural_net_predictions(model, x):\n",
    "  return (model.predict(x).flatten() > 0.5).astype(int)\n",
    "neural_net_predictions(shallow_nn, x_val)\n",
    "print(classification_report(y_val, neural_net_predictions(shallow_nn, x_val), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "477c2639-4211-4dd1-9fbf-68ba5ed566e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that the accuracy of the Fraud has increased significantly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dbd8f03-7ba2-45ad-b489-f78a45d659da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     28446\n",
      "       Fraud       0.77      0.49      0.60        35\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.89      0.74      0.80     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting the moodel in random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=2, n_jobs=-1)\n",
    "rf.fit(x_train, y_train)\n",
    "print(classification_report(y_val, rf.predict(x_val), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdf172c2-d21c-47e2-bf90-3e919805d7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     28446\n",
      "       Fraud       0.67      0.69      0.68        35\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.83      0.84      0.84     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Using gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "gbc.fit(x_train, y_train)\n",
    "print(classification_report(y_val, gbc.predict(x_val), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d1968f0-2140-49fe-8be3-b5b0b030352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     28446\n",
      "       Fraud       0.63      0.69      0.66        35\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.82      0.84      0.83     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(class_weight='balanced')\n",
    "svc.fit(x_train, y_train)\n",
    "print(classification_report(y_val, svc.predict(x_val), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16e513a8-905a-4386-8008-3cf9e25ed66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "1    492\n",
       "0    492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Creating a balanced dataset, with equal number of fraud and non fraud data\n",
    "not_frauds = new_df.query('Class == 0')\n",
    "frauds = new_df.query('Class == 1')\n",
    "not_frauds['Class'].value_counts(), frauds['Class'].value_counts()\n",
    "balanced_df = pd.concat([frauds, not_frauds.sample(len(frauds), random_state=1)])\n",
    "balanced_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "284ec090-b05b-4f48-addc-9159604901db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18372</th>\n",
       "      <td>0.170309</td>\n",
       "      <td>-1.762593</td>\n",
       "      <td>0.256143</td>\n",
       "      <td>1.683125</td>\n",
       "      <td>-1.279233</td>\n",
       "      <td>-1.902762</td>\n",
       "      <td>1.004210</td>\n",
       "      <td>-1.009748</td>\n",
       "      <td>-2.432546</td>\n",
       "      <td>0.458860</td>\n",
       "      <td>...</td>\n",
       "      <td>2.493579</td>\n",
       "      <td>0.320829</td>\n",
       "      <td>-0.535481</td>\n",
       "      <td>0.499401</td>\n",
       "      <td>-0.915196</td>\n",
       "      <td>-0.423434</td>\n",
       "      <td>0.107049</td>\n",
       "      <td>0.175922</td>\n",
       "      <td>2.906449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96341</th>\n",
       "      <td>0.380388</td>\n",
       "      <td>1.227614</td>\n",
       "      <td>-0.668974</td>\n",
       "      <td>-0.271785</td>\n",
       "      <td>-0.589440</td>\n",
       "      <td>-0.604795</td>\n",
       "      <td>-0.350285</td>\n",
       "      <td>-0.486365</td>\n",
       "      <td>-0.010809</td>\n",
       "      <td>-0.794944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026055</td>\n",
       "      <td>-0.295255</td>\n",
       "      <td>-0.180459</td>\n",
       "      <td>-0.436539</td>\n",
       "      <td>0.494649</td>\n",
       "      <td>-0.283738</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>1.062111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248296</th>\n",
       "      <td>0.890522</td>\n",
       "      <td>-0.613696</td>\n",
       "      <td>3.698772</td>\n",
       "      <td>-5.534941</td>\n",
       "      <td>5.620486</td>\n",
       "      <td>1.649263</td>\n",
       "      <td>-2.335145</td>\n",
       "      <td>-0.907188</td>\n",
       "      <td>0.706362</td>\n",
       "      <td>-3.747646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319261</td>\n",
       "      <td>-0.471379</td>\n",
       "      <td>-0.075890</td>\n",
       "      <td>-0.667909</td>\n",
       "      <td>-0.642848</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.488410</td>\n",
       "      <td>0.292345</td>\n",
       "      <td>-0.307413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264328</th>\n",
       "      <td>0.933932</td>\n",
       "      <td>-0.011624</td>\n",
       "      <td>0.640413</td>\n",
       "      <td>0.868046</td>\n",
       "      <td>-0.505279</td>\n",
       "      <td>0.261938</td>\n",
       "      <td>0.223098</td>\n",
       "      <td>0.239049</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.225142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069401</td>\n",
       "      <td>0.268024</td>\n",
       "      <td>0.261459</td>\n",
       "      <td>0.683742</td>\n",
       "      <td>-1.567901</td>\n",
       "      <td>-0.816674</td>\n",
       "      <td>0.185781</td>\n",
       "      <td>0.283021</td>\n",
       "      <td>-0.272619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208904</th>\n",
       "      <td>0.794730</td>\n",
       "      <td>-0.679341</td>\n",
       "      <td>1.217389</td>\n",
       "      <td>-0.316778</td>\n",
       "      <td>-1.086725</td>\n",
       "      <td>0.855349</td>\n",
       "      <td>-0.980760</td>\n",
       "      <td>0.970589</td>\n",
       "      <td>0.133116</td>\n",
       "      <td>-0.357671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083048</td>\n",
       "      <td>-0.137032</td>\n",
       "      <td>-0.238920</td>\n",
       "      <td>-0.617244</td>\n",
       "      <td>0.039020</td>\n",
       "      <td>-0.081848</td>\n",
       "      <td>0.234633</td>\n",
       "      <td>0.128382</td>\n",
       "      <td>-0.307273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81557</th>\n",
       "      <td>0.341393</td>\n",
       "      <td>-4.502731</td>\n",
       "      <td>-3.876484</td>\n",
       "      <td>1.341248</td>\n",
       "      <td>0.113400</td>\n",
       "      <td>0.189428</td>\n",
       "      <td>-0.560985</td>\n",
       "      <td>-0.140478</td>\n",
       "      <td>0.684651</td>\n",
       "      <td>0.475363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140218</td>\n",
       "      <td>0.049411</td>\n",
       "      <td>2.313731</td>\n",
       "      <td>0.252330</td>\n",
       "      <td>0.307219</td>\n",
       "      <td>0.859051</td>\n",
       "      <td>0.184033</td>\n",
       "      <td>-0.308269</td>\n",
       "      <td>4.227625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276071</th>\n",
       "      <td>0.965803</td>\n",
       "      <td>2.091900</td>\n",
       "      <td>-0.757459</td>\n",
       "      <td>-1.192258</td>\n",
       "      <td>-0.755458</td>\n",
       "      <td>-0.620324</td>\n",
       "      <td>-0.322077</td>\n",
       "      <td>-1.082511</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>-0.140927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288253</td>\n",
       "      <td>0.831939</td>\n",
       "      <td>0.142007</td>\n",
       "      <td>0.592615</td>\n",
       "      <td>-0.196143</td>\n",
       "      <td>-0.136676</td>\n",
       "      <td>0.020182</td>\n",
       "      <td>-0.015470</td>\n",
       "      <td>-0.028645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175971</th>\n",
       "      <td>0.709373</td>\n",
       "      <td>1.972989</td>\n",
       "      <td>0.157281</td>\n",
       "      <td>-1.715078</td>\n",
       "      <td>1.207451</td>\n",
       "      <td>0.681612</td>\n",
       "      <td>-0.615282</td>\n",
       "      <td>0.601791</td>\n",
       "      <td>-0.291935</td>\n",
       "      <td>-0.132265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098640</td>\n",
       "      <td>0.467533</td>\n",
       "      <td>-0.078973</td>\n",
       "      <td>-0.371882</td>\n",
       "      <td>0.486038</td>\n",
       "      <td>-0.490665</td>\n",
       "      <td>-0.018374</td>\n",
       "      <td>-0.070911</td>\n",
       "      <td>0.075735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27738</th>\n",
       "      <td>0.200727</td>\n",
       "      <td>-2.439237</td>\n",
       "      <td>2.591458</td>\n",
       "      <td>-2.840126</td>\n",
       "      <td>1.286244</td>\n",
       "      <td>-1.777016</td>\n",
       "      <td>-1.436139</td>\n",
       "      <td>-2.206056</td>\n",
       "      <td>-2.282725</td>\n",
       "      <td>-0.292885</td>\n",
       "      <td>...</td>\n",
       "      <td>1.774460</td>\n",
       "      <td>-0.771390</td>\n",
       "      <td>0.065727</td>\n",
       "      <td>0.103916</td>\n",
       "      <td>-0.057578</td>\n",
       "      <td>0.242652</td>\n",
       "      <td>-0.268649</td>\n",
       "      <td>-0.743713</td>\n",
       "      <td>1.443443</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156988</th>\n",
       "      <td>0.632535</td>\n",
       "      <td>0.745153</td>\n",
       "      <td>2.809299</td>\n",
       "      <td>-5.825406</td>\n",
       "      <td>5.835566</td>\n",
       "      <td>0.512320</td>\n",
       "      <td>-0.615622</td>\n",
       "      <td>-2.916576</td>\n",
       "      <td>0.776710</td>\n",
       "      <td>-1.878832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284841</td>\n",
       "      <td>-0.874383</td>\n",
       "      <td>-0.083995</td>\n",
       "      <td>-0.651442</td>\n",
       "      <td>0.454594</td>\n",
       "      <td>0.050376</td>\n",
       "      <td>0.756953</td>\n",
       "      <td>0.383869</td>\n",
       "      <td>-0.307413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "18372   0.170309 -1.762593  0.256143  1.683125 -1.279233 -1.902762  1.004210   \n",
       "96341   0.380388  1.227614 -0.668974 -0.271785 -0.589440 -0.604795 -0.350285   \n",
       "248296  0.890522 -0.613696  3.698772 -5.534941  5.620486  1.649263 -2.335145   \n",
       "264328  0.933932 -0.011624  0.640413  0.868046 -0.505279  0.261938  0.223098   \n",
       "208904  0.794730 -0.679341  1.217389 -0.316778 -1.086725  0.855349 -0.980760   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "81557   0.341393 -4.502731 -3.876484  1.341248  0.113400  0.189428 -0.560985   \n",
       "276071  0.965803  2.091900 -0.757459 -1.192258 -0.755458 -0.620324 -0.322077   \n",
       "175971  0.709373  1.972989  0.157281 -1.715078  1.207451  0.681612 -0.615282   \n",
       "27738   0.200727 -2.439237  2.591458 -2.840126  1.286244 -1.777016 -1.436139   \n",
       "156988  0.632535  0.745153  2.809299 -5.825406  5.835566  0.512320 -0.615622   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "18372  -1.009748 -2.432546  0.458860  ...  2.493579  0.320829 -0.535481   \n",
       "96341  -0.486365 -0.010809 -0.794944  ... -0.026055 -0.295255 -0.180459   \n",
       "248296 -0.907188  0.706362 -3.747646  ...  0.319261 -0.471379 -0.075890   \n",
       "264328  0.239049  0.150877  0.225142  ...  0.069401  0.268024  0.261459   \n",
       "208904  0.970589  0.133116 -0.357671  ... -0.083048 -0.137032 -0.238920   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "81557  -0.140478  0.684651  0.475363  ... -0.140218  0.049411  2.313731   \n",
       "276071 -1.082511  0.117200 -0.140927  ...  0.288253  0.831939  0.142007   \n",
       "175971  0.601791 -0.291935 -0.132265  ...  0.098640  0.467533 -0.078973   \n",
       "27738  -2.206056 -2.282725 -0.292885  ...  1.774460 -0.771390  0.065727   \n",
       "156988 -2.916576  0.776710 -1.878832  ...  0.284841 -0.874383 -0.083995   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  Class  \n",
       "18372   0.499401 -0.915196 -0.423434  0.107049  0.175922  2.906449      0  \n",
       "96341  -0.436539  0.494649 -0.283738 -0.001128  0.035075  1.062111      1  \n",
       "248296 -0.667909 -0.642848  0.070600  0.488410  0.292345 -0.307413      1  \n",
       "264328  0.683742 -1.567901 -0.816674  0.185781  0.283021 -0.272619      0  \n",
       "208904 -0.617244  0.039020 -0.081848  0.234633  0.128382 -0.307273      0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "81557   0.252330  0.307219  0.859051  0.184033 -0.308269  4.227625      0  \n",
       "276071  0.592615 -0.196143 -0.136676  0.020182 -0.015470 -0.028645      1  \n",
       "175971 -0.371882  0.486038 -0.490665 -0.018374 -0.070911  0.075735      0  \n",
       "27738   0.103916 -0.057578  0.242652 -0.268649 -0.743713  1.443443      1  \n",
       "156988 -0.651442  0.454594  0.050376  0.756953  0.383869 -0.307413      1  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df = balanced_df.sample(frac=1, random_state=1)\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "549716aa-9ff7-453b-a2a1-4a7f35553dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 30), (700,), (142, 30), (142,), (142, 30), (142,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_np = balanced_df.to_numpy()\n",
    "\n",
    "x_train_b, y_train_b = balanced_df_np[:700, :-1], balanced_df_np[:700, -1].astype(int)\n",
    "x_test_b, y_test_b = balanced_df_np[700:842, :-1], balanced_df_np[700:842, -1].astype(int)\n",
    "x_val_b, y_val_b = balanced_df_np[842:, :-1], balanced_df_np[842:, -1].astype(int)\n",
    "x_train_b.shape, y_train_b.shape, x_test_b.shape, y_test_b.shape, x_val_b.shape, y_val_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaf731df-7134-42ed-b0c7-eede4e12d85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    353\n",
       " 0    347\n",
       " Name: count, dtype: int64,\n",
       " 0    73\n",
       " 1    69\n",
       " Name: count, dtype: int64,\n",
       " 0    72\n",
       " 1    70\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train_b).value_counts(), pd.Series(y_test_b).value_counts(), pd.Series(y_val_b).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26ccb834-eeb3-4306-9d8c-25dbe3aa7e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.96      0.93      0.94        72\n",
      "       Fraud       0.93      0.96      0.94        70\n",
      "\n",
      "    accuracy                           0.94       142\n",
      "   macro avg       0.94      0.94      0.94       142\n",
      "weighted avg       0.94      0.94      0.94       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_model_b = LogisticRegression()\n",
    "logistic_model_b.fit(x_train_b, y_train_b)\n",
    "print(classification_report(y_val_b, logistic_model_b.predict(x_val_b), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c352df1-730f-4743-9d57-f3ed6f11cf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "17/22 [======================>.......] - ETA: 0s - loss: 1.1160 - accuracy: 0.3033 INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 38ms/step - loss: 1.1088 - accuracy: 0.3014 - val_loss: 1.4967 - val_accuracy: 0.5141\n",
      "Epoch 2/40\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.9754 - accuracy: 0.4114INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 38ms/step - loss: 0.9754 - accuracy: 0.4114 - val_loss: 1.0361 - val_accuracy: 0.5704\n",
      "Epoch 3/40\n",
      "18/22 [=======================>......] - ETA: 0s - loss: 0.8261 - accuracy: 0.5417INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 32ms/step - loss: 0.8288 - accuracy: 0.5414 - val_loss: 0.7944 - val_accuracy: 0.6479\n",
      "Epoch 4/40\n",
      "12/22 [===============>..............] - ETA: 0s - loss: 0.7579 - accuracy: 0.6042INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 31ms/step - loss: 0.7446 - accuracy: 0.6114 - val_loss: 0.6909 - val_accuracy: 0.6901\n",
      "Epoch 5/40\n",
      "12/22 [===============>..............] - ETA: 0s - loss: 0.6864 - accuracy: 0.6510INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 32ms/step - loss: 0.6862 - accuracy: 0.6429 - val_loss: 0.6298 - val_accuracy: 0.7254\n",
      "Epoch 6/40\n",
      "14/22 [==================>...........] - ETA: 0s - loss: 0.6440 - accuracy: 0.6920INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 45ms/step - loss: 0.6490 - accuracy: 0.6771 - val_loss: 0.5922 - val_accuracy: 0.7394\n",
      "Epoch 7/40\n",
      "17/22 [======================>.......] - ETA: 0s - loss: 0.6422 - accuracy: 0.6875INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 31ms/step - loss: 0.6270 - accuracy: 0.6943 - val_loss: 0.5613 - val_accuracy: 0.7535\n",
      "Epoch 8/40\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.6078 - accuracy: 0.7158INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 74ms/step - loss: 0.6025 - accuracy: 0.7171 - val_loss: 0.5339 - val_accuracy: 0.8028\n",
      "Epoch 9/40\n",
      "17/22 [======================>.......] - ETA: 0s - loss: 0.5744 - accuracy: 0.7353INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 30ms/step - loss: 0.5834 - accuracy: 0.7343 - val_loss: 0.5156 - val_accuracy: 0.8099\n",
      "Epoch 10/40\n",
      "13/22 [================>.............] - ETA: 0s - loss: 0.5573 - accuracy: 0.7524INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 33ms/step - loss: 0.5624 - accuracy: 0.7471 - val_loss: 0.4976 - val_accuracy: 0.8310\n",
      "Epoch 11/40\n",
      "11/22 [==============>...............] - ETA: 0s - loss: 0.5454 - accuracy: 0.7301INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 33ms/step - loss: 0.5401 - accuracy: 0.7543 - val_loss: 0.4829 - val_accuracy: 0.8380\n",
      "Epoch 12/40\n",
      "10/22 [============>.................] - ETA: 0s - loss: 0.5444 - accuracy: 0.7844INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 32ms/step - loss: 0.5253 - accuracy: 0.7657 - val_loss: 0.4651 - val_accuracy: 0.8451\n",
      "Epoch 13/40\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 0.5042 - accuracy: 0.7979INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 59ms/step - loss: 0.5141 - accuracy: 0.7929 - val_loss: 0.4486 - val_accuracy: 0.8451\n",
      "Epoch 14/40\n",
      "19/22 [========================>.....] - ETA: 0s - loss: 0.4912 - accuracy: 0.8109INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 42ms/step - loss: 0.4892 - accuracy: 0.8186 - val_loss: 0.4336 - val_accuracy: 0.8521\n",
      "Epoch 15/40\n",
      "18/22 [=======================>......] - ETA: 0s - loss: 0.4737 - accuracy: 0.8160INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 126ms/step - loss: 0.4690 - accuracy: 0.8357 - val_loss: 0.4234 - val_accuracy: 0.8873\n",
      "Epoch 16/40\n",
      "14/22 [==================>...........] - ETA: 0s - loss: 0.4850 - accuracy: 0.8348INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 54ms/step - loss: 0.4648 - accuracy: 0.8357 - val_loss: 0.4074 - val_accuracy: 0.9014\n",
      "Epoch 17/40\n",
      "14/22 [==================>...........] - ETA: 0s - loss: 0.4507 - accuracy: 0.8638INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 65ms/step - loss: 0.4506 - accuracy: 0.8500 - val_loss: 0.3998 - val_accuracy: 0.9014\n",
      "Epoch 18/40\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.3746 - accuracy: 1.0000INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 52ms/step - loss: 0.4308 - accuracy: 0.8686 - val_loss: 0.3881 - val_accuracy: 0.9155\n",
      "Epoch 19/40\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.4279 - accuracy: 0.7812INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 53ms/step - loss: 0.4163 - accuracy: 0.8843 - val_loss: 0.3767 - val_accuracy: 0.9225\n",
      "Epoch 20/40\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.3840 - accuracy: 0.9375INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 38ms/step - loss: 0.4065 - accuracy: 0.9029 - val_loss: 0.3614 - val_accuracy: 0.9296\n",
      "Epoch 21/40\n",
      "17/22 [======================>.......] - ETA: 0s - loss: 0.3761 - accuracy: 0.9099INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 41ms/step - loss: 0.3872 - accuracy: 0.8943 - val_loss: 0.3539 - val_accuracy: 0.9296\n",
      "Epoch 22/40\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 0.3814 - accuracy: 0.9062INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 75ms/step - loss: 0.3783 - accuracy: 0.9029 - val_loss: 0.3482 - val_accuracy: 0.9366\n",
      "Epoch 23/40\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.3766 - accuracy: 0.9375INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 49ms/step - loss: 0.3711 - accuracy: 0.9171 - val_loss: 0.3386 - val_accuracy: 0.9437\n",
      "Epoch 24/40\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 0.3537 - accuracy: 0.9277INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 81ms/step - loss: 0.3549 - accuracy: 0.9171 - val_loss: 0.3299 - val_accuracy: 0.9366\n",
      "Epoch 25/40\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.4839 - accuracy: 0.8750INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 54ms/step - loss: 0.3550 - accuracy: 0.9114 - val_loss: 0.3210 - val_accuracy: 0.9366\n",
      "Epoch 26/40\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.3423 - accuracy: 0.9182INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 60ms/step - loss: 0.3420 - accuracy: 0.9171 - val_loss: 0.3148 - val_accuracy: 0.9366\n",
      "Epoch 27/40\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 0.2252 - accuracy: 1.0000INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 138ms/step - loss: 0.3270 - accuracy: 0.9271 - val_loss: 0.3095 - val_accuracy: 0.9366\n",
      "Epoch 28/40\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.3190 - accuracy: 0.9211INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 5s 221ms/step - loss: 0.3183 - accuracy: 0.9200 - val_loss: 0.2955 - val_accuracy: 0.9366\n",
      "Epoch 29/40\n",
      "13/22 [================>.............] - ETA: 0s - loss: 0.3106 - accuracy: 0.9231INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 86ms/step - loss: 0.3124 - accuracy: 0.9229 - val_loss: 0.2929 - val_accuracy: 0.9437\n",
      "Epoch 30/40\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.9243INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 113ms/step - loss: 0.2992 - accuracy: 0.9243 - val_loss: 0.2857 - val_accuracy: 0.9437\n",
      "Epoch 31/40\n",
      "18/22 [=======================>......] - ETA: 0s - loss: 0.2911 - accuracy: 0.9253INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 4s 196ms/step - loss: 0.2952 - accuracy: 0.9229 - val_loss: 0.2718 - val_accuracy: 0.9437\n",
      "Epoch 32/40\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 0.2805 - accuracy: 0.9312INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 129ms/step - loss: 0.2834 - accuracy: 0.9286 - val_loss: 0.2700 - val_accuracy: 0.9437\n",
      "Epoch 33/40\n",
      "12/22 [===============>..............] - ETA: 0s - loss: 0.2746 - accuracy: 0.9401INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 65ms/step - loss: 0.2864 - accuracy: 0.9357 - val_loss: 0.2611 - val_accuracy: 0.9437\n",
      "Epoch 34/40\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 0.2752 - accuracy: 0.9146INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 102ms/step - loss: 0.2675 - accuracy: 0.9286 - val_loss: 0.2580 - val_accuracy: 0.9437\n",
      "Epoch 35/40\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2676 - accuracy: 0.9329INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 156ms/step - loss: 0.2676 - accuracy: 0.9329 - val_loss: 0.2528 - val_accuracy: 0.9437\n",
      "Epoch 36/40\n",
      "18/22 [=======================>......] - ETA: 0s - loss: 0.2595 - accuracy: 0.9392INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 5s 214ms/step - loss: 0.2521 - accuracy: 0.9414 - val_loss: 0.2431 - val_accuracy: 0.9437\n",
      "Epoch 37/40\n",
      "19/22 [========================>.....] - ETA: 0s - loss: 0.2464 - accuracy: 0.9359INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 104ms/step - loss: 0.2478 - accuracy: 0.9357 - val_loss: 0.2350 - val_accuracy: 0.9437\n",
      "Epoch 38/40\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2459 - accuracy: 0.9357INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 145ms/step - loss: 0.2459 - accuracy: 0.9357 - val_loss: 0.2335 - val_accuracy: 0.9366\n",
      "Epoch 39/40\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 0.2289 - accuracy: 0.9391INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 94ms/step - loss: 0.2328 - accuracy: 0.9400 - val_loss: 0.2276 - val_accuracy: 0.9437\n",
      "Epoch 40/40\n",
      "12/22 [===============>..............] - ETA: 0s - loss: 0.2143 - accuracy: 0.9453INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 80ms/step - loss: 0.2307 - accuracy: 0.9414 - val_loss: 0.2221 - val_accuracy: 0.9507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x131742310>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_nn_b = Sequential()\n",
    "shallow_nn_b.add(InputLayer((x_train.shape[1],)))\n",
    "shallow_nn_b.add(Dense(2, 'relu'))\n",
    "shallow_nn_b.add(BatchNormalization())\n",
    "shallow_nn_b.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "checkpoint = ModelCheckpoint('shallow_nn_b', save_best_only=True)\n",
    "shallow_nn_b.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "shallow_nn_b.fit(x_train_b, y_train_b, validation_data=(x_val_b, y_val_b), epochs=40, callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71f1e990-b5e2-42e5-a4d0-355031664f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "18/22 [=======================>......] - ETA: 0s - loss: 0.2347 - accuracy: 0.9392INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 4s 195ms/step - loss: 0.2322 - accuracy: 0.9386 - val_loss: 0.2174 - val_accuracy: 0.9507\n",
      "Epoch 2/40\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.2269 - accuracy: 0.9386 - val_loss: 0.2180 - val_accuracy: 0.9507\n",
      "Epoch 3/40\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.9386INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 156ms/step - loss: 0.2155 - accuracy: 0.9386 - val_loss: 0.2127 - val_accuracy: 0.9507\n",
      "Epoch 4/40\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 0.2117 - accuracy: 0.9406INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 142ms/step - loss: 0.2133 - accuracy: 0.9414 - val_loss: 0.2063 - val_accuracy: 0.9507\n",
      "Epoch 5/40\n",
      "13/22 [================>.............] - ETA: 0s - loss: 0.2035 - accuracy: 0.9519INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 64ms/step - loss: 0.2116 - accuracy: 0.9457 - val_loss: 0.2013 - val_accuracy: 0.9507\n",
      "Epoch 6/40\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 0.2034 - accuracy: 0.9500INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 62ms/step - loss: 0.2058 - accuracy: 0.9486 - val_loss: 0.1978 - val_accuracy: 0.9507\n",
      "Epoch 7/40\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 0.2095 - accuracy: 0.9469INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 96ms/step - loss: 0.2100 - accuracy: 0.9443 - val_loss: 0.1955 - val_accuracy: 0.9437\n",
      "Epoch 8/40\n",
      "18/22 [=======================>......] - ETA: 0s - loss: 0.2013 - accuracy: 0.9427INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 86ms/step - loss: 0.2001 - accuracy: 0.9471 - val_loss: 0.1942 - val_accuracy: 0.9437\n",
      "Epoch 9/40\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 0.2212 - accuracy: 0.9434INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 73ms/step - loss: 0.2054 - accuracy: 0.9471 - val_loss: 0.1910 - val_accuracy: 0.9437\n",
      "Epoch 10/40\n",
      "17/22 [======================>.......] - ETA: 0s - loss: 0.1798 - accuracy: 0.9540INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 87ms/step - loss: 0.1981 - accuracy: 0.9400 - val_loss: 0.1898 - val_accuracy: 0.9437\n",
      "Epoch 11/40\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 0.1877 - accuracy: 0.9500INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 57ms/step - loss: 0.2066 - accuracy: 0.9457 - val_loss: 0.1876 - val_accuracy: 0.9437\n",
      "Epoch 12/40\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 0.1941 - accuracy: 0.9422INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 63ms/step - loss: 0.1950 - accuracy: 0.9443 - val_loss: 0.1840 - val_accuracy: 0.9437\n",
      "Epoch 13/40\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9414INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 108ms/step - loss: 0.1887 - accuracy: 0.9414 - val_loss: 0.1818 - val_accuracy: 0.9437\n",
      "Epoch 14/40\n",
      "19/22 [========================>.....] - ETA: 0s - loss: 0.1804 - accuracy: 0.9457INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 86ms/step - loss: 0.1958 - accuracy: 0.9386 - val_loss: 0.1809 - val_accuracy: 0.9437\n",
      "Epoch 15/40\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 0.1880 - accuracy: 0.9484INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 71ms/step - loss: 0.1856 - accuracy: 0.9486 - val_loss: 0.1808 - val_accuracy: 0.9366\n",
      "Epoch 16/40\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.1824 - accuracy: 0.9443 - val_loss: 0.1823 - val_accuracy: 0.9366\n",
      "Epoch 17/40\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9400INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 60ms/step - loss: 0.1808 - accuracy: 0.9400 - val_loss: 0.1786 - val_accuracy: 0.9366\n",
      "Epoch 18/40\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1716 - accuracy: 0.9486 - val_loss: 0.1795 - val_accuracy: 0.9366\n",
      "Epoch 19/40\n",
      "17/22 [======================>.......] - ETA: 0s - loss: 0.1792 - accuracy: 0.9467INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 59ms/step - loss: 0.1820 - accuracy: 0.9443 - val_loss: 0.1756 - val_accuracy: 0.9366\n",
      "Epoch 20/40\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.9429INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 64ms/step - loss: 0.1733 - accuracy: 0.9429 - val_loss: 0.1752 - val_accuracy: 0.9366\n",
      "Epoch 21/40\n",
      "19/22 [========================>.....] - ETA: 0s - loss: 0.1628 - accuracy: 0.9539INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 93ms/step - loss: 0.1681 - accuracy: 0.9486 - val_loss: 0.1726 - val_accuracy: 0.9366\n",
      "Epoch 22/40\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.9414INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 107ms/step - loss: 0.1837 - accuracy: 0.9414 - val_loss: 0.1712 - val_accuracy: 0.9366\n",
      "Epoch 23/40\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.1731 - accuracy: 0.9429 - val_loss: 0.1722 - val_accuracy: 0.9366\n",
      "Epoch 24/40\n",
      "18/22 [=======================>......] - ETA: 0s - loss: 0.1687 - accuracy: 0.9375INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 63ms/step - loss: 0.1678 - accuracy: 0.9386 - val_loss: 0.1651 - val_accuracy: 0.9366\n",
      "Epoch 25/40\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1745 - accuracy: 0.9471 - val_loss: 0.1675 - val_accuracy: 0.9366\n",
      "Epoch 26/40\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.1694 - accuracy: 0.9457 - val_loss: 0.1669 - val_accuracy: 0.9366\n",
      "Epoch 27/40\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.1750 - accuracy: 0.9429 - val_loss: 0.1673 - val_accuracy: 0.9366\n",
      "Epoch 28/40\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.1624 - accuracy: 0.9486 - val_loss: 0.1660 - val_accuracy: 0.9366\n",
      "Epoch 29/40\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.9529INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 57ms/step - loss: 0.1523 - accuracy: 0.9529 - val_loss: 0.1628 - val_accuracy: 0.9366\n",
      "Epoch 30/40\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.1586 - accuracy: 0.9543 - val_loss: 0.1638 - val_accuracy: 0.9366\n",
      "Epoch 31/40\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 0.1627 - accuracy: 0.9524INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 89ms/step - loss: 0.1615 - accuracy: 0.9529 - val_loss: 0.1626 - val_accuracy: 0.9366\n",
      "Epoch 32/40\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1631 - accuracy: 0.9371INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 7s 340ms/step - loss: 0.1631 - accuracy: 0.9371 - val_loss: 0.1618 - val_accuracy: 0.9366\n",
      "Epoch 33/40\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 0.1626 - accuracy: 0.9486 - val_loss: 0.1627 - val_accuracy: 0.9366\n",
      "Epoch 34/40\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.9443INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 7s 329ms/step - loss: 0.1671 - accuracy: 0.9443 - val_loss: 0.1599 - val_accuracy: 0.9437\n",
      "Epoch 35/40\n",
      "13/22 [================>.............] - ETA: 0s - loss: 0.1721 - accuracy: 0.9327INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 4s 192ms/step - loss: 0.1649 - accuracy: 0.9414 - val_loss: 0.1588 - val_accuracy: 0.9437\n",
      "Epoch 36/40\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.1601 - accuracy: 0.9429 - val_loss: 0.1600 - val_accuracy: 0.9437\n",
      "Epoch 37/40\n",
      "17/22 [======================>.......] - ETA: 0s - loss: 0.1590 - accuracy: 0.9393INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 7s 344ms/step - loss: 0.1615 - accuracy: 0.9400 - val_loss: 0.1587 - val_accuracy: 0.9437\n",
      "Epoch 38/40\n",
      "14/22 [==================>...........] - ETA: 0s - loss: 0.1832 - accuracy: 0.9375INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: shallow_nn_b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 126ms/step - loss: 0.1647 - accuracy: 0.9457 - val_loss: 0.1584 - val_accuracy: 0.9437\n",
      "Epoch 39/40\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1614 - accuracy: 0.9471 - val_loss: 0.1592 - val_accuracy: 0.9437\n",
      "Epoch 40/40\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.1592 - accuracy: 0.9429 - val_loss: 0.1585 - val_accuracy: 0.9437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x130df9c90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_nn_b.fit(x_train_b, y_train_b, validation_data=(x_val_b, y_val_b), epochs=40, callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "523a5911-7415-40a4-937f-edece12691a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 15ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.96      0.93      0.94        72\n",
      "       Fraud       0.93      0.96      0.94        70\n",
      "\n",
      "    accuracy                           0.94       142\n",
      "   macro avg       0.94      0.94      0.94       142\n",
      "weighted avg       0.94      0.94      0.94       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_b, neural_net_predictions(shallow_nn_b, x_val_b), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c60d5282-150d-41a3-8dff-c8c81b3b0347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.69      1.00      0.82        72\n",
      "       Fraud       1.00      0.54      0.70        70\n",
      "\n",
      "    accuracy                           0.77       142\n",
      "   macro avg       0.85      0.77      0.76       142\n",
      "weighted avg       0.84      0.77      0.76       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_b = RandomForestClassifier(max_depth=2, n_jobs=-1)\n",
    "rf_b.fit(x_train_b, y_train_b)\n",
    "print(classification_report(y_val_b, rf.predict(x_val_b), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fa3c8b9-3b7d-465b-b5c9-d3735b35e2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.81      1.00      0.89        72\n",
      "       Fraud       1.00      0.76      0.86        70\n",
      "\n",
      "    accuracy                           0.88       142\n",
      "   macro avg       0.90      0.88      0.88       142\n",
      "weighted avg       0.90      0.88      0.88       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbc_b = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=2, random_state=0)\n",
    "gbc_b.fit(x_train_b, y_train_b)\n",
    "print(classification_report(y_val_b, gbc.predict(x_val_b), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76e8eabd-3279-49dd-92f3-707571fd9ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       0.88      1.00      0.94        72\n",
      "       Fraud       1.00      0.86      0.92        70\n",
      "\n",
      "    accuracy                           0.93       142\n",
      "   macro avg       0.94      0.93      0.93       142\n",
      "weighted avg       0.94      0.93      0.93       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_b = LinearSVC(class_weight='balanced')\n",
    "svc_b.fit(x_train_b, y_train_b)\n",
    "print(classification_report(y_val_b, svc.predict(x_val_b), target_names=['Not Fraud', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b6e34-803c-425a-9b20-7038a43e107a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
